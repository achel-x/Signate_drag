{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking 实现\n",
    "## 一、使用的数据集\n",
    "处理后的原训练集 特征数据：dg_pca_train<br />\n",
    "处理后的原训练集合 得分数据：score_train<br />\n",
    "处理后的测试集合：dg_pca_test<br />\n",
    "测试集序号：id_test<br />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#预设导入\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#机器学习导入\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import explained_variance_score \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import ensemble\n",
    "from sklearn import neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取本地数据集\n",
    "dg_pca_train=pd.read_csv('dg_pca_train.csv').values\n",
    "dg_pca_test=pd.read_csv('dg_pca_test.csv').values\n",
    "\n",
    "id_test=pd.read_csv('id_test.csv').values\n",
    "id_train=pd.read_csv('id_train.csv').values\n",
    "score_train=pd.read_csv('score_train.csv').values\n",
    "id_train=id_train.flatten()\n",
    "id_test=id_test.flatten()#ID二维数组转一维"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stacking过程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 新数据集\n",
    "X:处理后的原训练集 特征数据：dg_pca_train<br />\n",
    "y:处理后的原训练集 得分数据：score_train<br />\n",
    "X_predict:处理后的测试集合 特征数据：dg_pca_test<br />\n",
    "y_predict:NA<br />\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                      n_jobs=None, oob_score=False, random_state=None,\n",
      "                      verbose=0, warm_start=False)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "1 SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=0.0001,\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "2 XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
      "             max_depth=3, min_child_weight=5, missing=None, n_estimators=1200,\n",
      "             n_jobs=1, nthread=None, objective='reg:linear', random_state=161,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "             silent=None, subsample=1, verbosity=1)\n",
      "Fold 0\n",
      "[05:24:27] WARNING: d:\\build\\xgboost\\xgboost-0.90.git\\src\\objective\\regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fold 1\n",
      "[05:37:03] WARNING: d:\\build\\xgboost\\xgboost-0.90.git\\src\\objective\\regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fold 2\n",
      "[05:49:28] WARNING: d:\\build\\xgboost\\xgboost-0.90.git\\src\\objective\\regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fold 3\n",
      "[06:01:56] WARNING: d:\\build\\xgboost\\xgboost-0.90.git\\src\\objective\\regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fold 4\n",
      "[06:14:09] WARNING: d:\\build\\xgboost\\xgboost-0.90.git\\src\\objective\\regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "# '''创建训练的数据集'''\n",
    "#data, target = make_blobs(n_samples=50000, centers=2, random_state=0, cluster_std=0.60)\n",
    " \n",
    "# '''模型融合中使用到的各个单模型'''\n",
    "clfs = [RandomForestRegressor(n_estimators=500),\n",
    "        svm.SVR(kernel='rbf',C=10,gamma=0.0001),\n",
    "        XGBRegressor(max_depth=3,min_child_weight=5,learning_rate=0.1,n_estimators=1200,random_state=161)]\n",
    " \n",
    "#'''切分一部分数据作为测试集'''\n",
    "X=dg_pca_train\n",
    "X_predict=dg_pca_test\n",
    "y=score_train\n",
    "#y_predict = \n",
    "\n",
    "\n",
    "dataset_blend_train = np.zeros((X.shape[0], len(clfs)))#第一轮 保存各个模型在训练集上的预测结果 训练集合个数×模型数\n",
    "dataset_blend_test = np.zeros((X_predict.shape[0], len(clfs)))#第一轮 保存各个模型在测试集上的预测结果 训练集合个数×模型数\n",
    "\n",
    "#'''5折stacking'''\n",
    "n_folds = 5\n",
    "kf = KFold(n_folds,True,50)\n",
    "skf=list(kf.split(X))#X或者y\n",
    "\n",
    "for j, clf in enumerate(clfs):\n",
    "    #'''依次训练各个单模型'''\n",
    "    print(j, clf)\n",
    "    dataset_blend_test_j = np.zeros((X_predict.shape[0], len(skf)))#存目前这个模型上的测试集结果(之后求平均)\n",
    "    for i, (train, test) in enumerate(skf):\n",
    "        #'''使用第i个部分作为预测，剩余的部分来训练模型，获得其预测的输出作为第i部分的新特征。'''\n",
    "        print(\"Fold\", i)\n",
    "        X_train, y_train, X_test, y_test = X[train], y[train], X[test], y[test]\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_submission = clf.predict(X_test)#1fold的预测结果\n",
    "        \n",
    "        #y_submission.reshape(len(y_submission),1)#一维数组转二维 可以不加\n",
    "        \n",
    "        dataset_blend_train[test, j] = y_submission#在模型顺序对应的j位置 存1fold的预测结果\n",
    "        dataset_blend_test_j[:, i] = clf.predict(X_predict)#存该模型该折下的测试集预测结果\n",
    "        \n",
    "    #'''对于测试集，直接用这k个模型的预测值均值作为新的特征。'''\n",
    "    dataset_blend_test[:, j] = dataset_blend_test_j.mean(1)#测试集结果按行取平均后储存\n",
    "    \n",
    "    \n",
    "    #print(\"val auc Score: %f\" % r2_score(y_predict, dataset_blend_test[:, j]))\n",
    "    \n",
    "    #保存模型\n",
    "    fl_name=\"stacking_{0}\".format(j)\n",
    "    joblib.dump(clf, fl_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_blend_train_1=dataset_blend_train\n",
    "dataset_blend_test_1=dataset_blend_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=None, n_neighbors=9, p=2,\n",
      "                    weights='distance')\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "1 GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "                          learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                          n_iter_no_change=None, presort='auto',\n",
      "                          random_state=None, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n"
     ]
    }
   ],
   "source": [
    "# '''创建训练的数据集'''\n",
    "#data, target = make_blobs(n_samples=50000, centers=2, random_state=0, cluster_std=0.60)\n",
    " \n",
    "# '''模型融合中使用到的各个单模型'''\n",
    "clfs = [neighbors.KNeighborsRegressor(n_neighbors=9, p=2,weights='distance'),\n",
    "        ensemble.GradientBoostingRegressor(n_estimators=500)]\n",
    " \n",
    "#'''切分一部分数据作为测试集'''\n",
    "X=dg_pca_train\n",
    "X_predict=dg_pca_test\n",
    "y=score_train\n",
    "#y_predict = \n",
    "\n",
    "\n",
    "dataset_blend_train_2 = np.zeros((X.shape[0], len(clfs)))#第一轮 保存各个模型在训练集上的预测结果 训练集合个数×模型数\n",
    "dataset_blend_test_2 = np.zeros((X_predict.shape[0], len(clfs)))#第一轮 保存各个模型在测试集上的预测结果 训练集合个数×模型数\n",
    "\n",
    "#'''5折stacking'''\n",
    "n_folds = 5\n",
    "kf = KFold(n_folds,True,50)\n",
    "skf=list(kf.split(X))#X或者y\n",
    "\n",
    "for j, clf in enumerate(clfs):\n",
    "    #'''依次训练各个单模型'''\n",
    "    print(j, clf)\n",
    "    dataset_blend_test_j = np.zeros((X_predict.shape[0], len(skf)))#存目前这个模型上的测试集结果(之后求平均)\n",
    "    for i, (train, test) in enumerate(skf):\n",
    "        #'''使用第i个部分作为预测，剩余的部分来训练模型，获得其预测的输出作为第i部分的新特征。'''\n",
    "        print(\"Fold\", i)\n",
    "        X_train, y_train, X_test, y_test = X[train], y[train], X[test], y[test]\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_submission = clf.predict(X_test)#1fold的预测结果\n",
    "        y_submission=y_submission.flatten()#2维数组转1维 KNN需要 \n",
    "        #y_submission.reshape(len(y_submission),1)#一维数组转二维 可以不加\n",
    "        \n",
    "        dataset_blend_train_2[test, j] = y_submission#在模型顺序对应的j位置 存1fold的预测结果\n",
    "        dataset_blend_test_j[:, i] = clf.predict(X_predict).flatten()#存该模型该折下的测试集预测结果\n",
    "        \n",
    "    #'''对于测试集，直接用这k个模型的预测值均值作为新的特征。'''\n",
    "    dataset_blend_test_2[:, j] = dataset_blend_test_j.mean(1)#测试集结果按行取平均后储存\n",
    "    \n",
    "    \n",
    "    #print(\"val auc Score: %f\" % r2_score(y_predict, dataset_blend_test[:, j]))\n",
    "    \n",
    "    #保存模型\n",
    "    fl_name=\"stacking_{0}\".format(j+2)\n",
    "    joblib.dump(clf, fl_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_blend_train_2=dataset_blend_train_2[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导出数据集到本地\n",
    "submission_train_1=pd.DataFrame(dataset_blend_train_2)\n",
    "#submission_train_1.head()\n",
    "submission_train_1.to_csv('dataset_blend_train_2.csv',index=False)#第一轮训练后 train集合预测得到的score集合 训练集样本数x3个模型\n",
    "\n",
    "submission_test_1=pd.DataFrame(dataset_blend_test_2)\n",
    "#submission_test_1.head()\n",
    "submission_test_1.to_csv('dataset_blend_test_2.csv',index=False)#第一轮训练后 test集合预测得到的score集合 测试机样本数x3个模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#拼合数据\n",
    "dataset_blend_test=np.hstack((dataset_blend_test_1,dataset_blend_test_2))\n",
    "dataset_blend_train=np.hstack((dataset_blend_train_1,dataset_blend_train_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.55434901, 1.71705025, 1.72925215, 1.30136768, 1.70438694],\n",
       "       [2.32998628, 2.6439508 , 2.60908222, 2.41936645, 2.59386453],\n",
       "       [2.49372005, 2.33086505, 2.69724541, 2.64994564, 2.67796928],\n",
       "       ...,\n",
       "       [1.88082266, 2.31558535, 1.82576983, 2.25811547, 2.07382897],\n",
       "       [2.36509145, 2.30614058, 2.31984725, 2.2470369 , 2.26451797],\n",
       "       [2.50106031, 2.5574335 , 2.54165936, 2.56390571, 2.57053153]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_blend_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.30136768, 1.70438694],\n",
       "       [2.41936645, 2.59386453],\n",
       "       [2.64994564, 2.67796928],\n",
       "       ...,\n",
       "       [2.25811547, 2.07382897],\n",
       "       [2.2470369 , 2.26451797],\n",
       "       [2.56390571, 2.57053153]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_blend_test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第二轮\n",
    "clf = svm.SVR(C=1.0,gamma=0.1)\n",
    "\n",
    "clf.fit(dataset_blend_train, y)\n",
    "y_submission = clf.predict(dataset_blend_test)\n",
    "\n",
    "#生成文件\n",
    "submission_df=pd.DataFrame(data={'Id':id_test,'SalePrice':y_submission})\n",
    "submission_df.head()\n",
    "submission_df.to_csv('baseline_st5.csv',header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.30136768, 1.70438694],\n",
       "       [2.41936645, 2.59386453],\n",
       "       [2.64994564, 2.67796928],\n",
       "       ...,\n",
       "       [2.25811547, 2.07382897],\n",
       "       [2.2470369 , 2.26451797],\n",
       "       [2.56390571, 2.57053153]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_blend_test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
      "    gamma='auto_deprecated', kernel='rbf', max_iter=-1, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVR()\n",
    "print(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10984, 5) (10984, 1) (2747, 5) (2747, 1)\n",
      "r2\n",
      "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=0.1,\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
      "0.527(+/-0.008) for {'C': 1.0, 'gamma': 0.0001}\n",
      "0.569(+/-0.007) for {'C': 1.0, 'gamma': 0.001}\n",
      "0.574(+/-0.008) for {'C': 1.0, 'gamma': 0.01}\n",
      "0.575(+/-0.009) for {'C': 1.0, 'gamma': 0.1}\n",
      "0.569(+/-0.010) for {'C': 1.0, 'gamma': 1.0}\n",
      "0.568(+/-0.007) for {'C': 10.0, 'gamma': 0.0001}\n",
      "0.573(+/-0.008) for {'C': 10.0, 'gamma': 0.001}\n",
      "0.574(+/-0.008) for {'C': 10.0, 'gamma': 0.01}\n",
      "0.574(+/-0.009) for {'C': 10.0, 'gamma': 0.1}\n",
      "0.557(+/-0.011) for {'C': 10.0, 'gamma': 1.0}\n",
      "0.572(+/-0.008) for {'C': 100.0, 'gamma': 0.0001}\n",
      "0.573(+/-0.008) for {'C': 100.0, 'gamma': 0.001}\n",
      "0.575(+/-0.008) for {'C': 100.0, 'gamma': 0.01}\n",
      "0.572(+/-0.008) for {'C': 100.0, 'gamma': 0.1}\n",
      "0.520(+/-0.009) for {'C': 100.0, 'gamma': 1.0}\n",
      "0.572(+/-0.008) for {'C': 1000.0, 'gamma': 0.0001}\n",
      "0.573(+/-0.008) for {'C': 1000.0, 'gamma': 0.001}\n",
      "0.575(+/-0.009) for {'C': 1000.0, 'gamma': 0.01}\n",
      "0.568(+/-0.007) for {'C': 1000.0, 'gamma': 0.1}\n",
      "0.398(+/-0.025) for {'C': 1000.0, 'gamma': 1.0}\n"
     ]
    }
   ],
   "source": [
    "#调参数\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset_blend_train, y, test_size=0.2, random_state=123)\n",
    "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)\n",
    "\n",
    "#SVR模型调参数：C gamma\n",
    "param_g=[{\"C\": [1e0, 1e1, 1e2, 1e3],\"gamma\": np.logspace(-4, 0, 5)}]\n",
    "scores_g=['r2']\n",
    "for score in scores_g:\n",
    "    print(score)\n",
    "    clf=GridSearchCV(svm.SVR(),param_grid=param_g,cv=3,scoring=score)\n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "    print(clf.best_estimator_)\n",
    "    \n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds=clf.cv_results_['std_test_score']\n",
    "    params = clf.cv_results_['params']\n",
    "    \n",
    "    for (param,mean_score,std_score) in zip(params,means,stds):\n",
    "        print(\"%0.3f(+/-%0.03f) for %r\"%(mean_score,std_score,param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clfs = [RandomForestRegressor(),\n",
    "#         svm.SVR(),\n",
    "#         XGBRegressor()]\n",
    "# for j, clf in enumerate(clfs):\n",
    "#     fl_name=\"stacking_{0}\".format(j)\n",
    "#     joblib.dump(clf, fl_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#在独立测试集上预测数据\n",
    "svc_best_predict=svc_best.predict(dg_pca_test)\n",
    "print(svc_best_predict)\n",
    "np.shape(svc_best_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SVR' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-df3c5a134293>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'SVR' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "print(clf.best_estimator_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
